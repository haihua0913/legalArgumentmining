{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Co_Training_2C.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsuEQpNSYpvpyTbmN6J4qV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssvadla/Legal_Text_Classification/blob/main/Co_Training_2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aon0xVdtVTO8",
        "outputId": "ee5e021e-d5a5-445d-f3a3-6e6bdde646b5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from google.colab import drive\n",
        "import math\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnrSKGN_nTN2"
      },
      "source": [
        "record_unlabel_list = []\n",
        "record_f1_score = []\n",
        "record_CR = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgL93QrEzVjo"
      },
      "source": [
        "#Co-training Algorithm\n",
        "\n",
        "def training(unlabel_1,train,i,j):\n",
        "    train_size = len(train)\n",
        "    record_unlabel_list.append(train_size - 4416)\n",
        "    target_values = np.unique(train['Target'].values)\n",
        "\n",
        "    data_list = []\n",
        "    data_length_list = []\n",
        "    for i in target_values:\n",
        "      df_k = train[train['Target']==i]\n",
        "      data_list.append(df_k)\n",
        "      data_length_list.append(len(df_k))\n",
        "   \n",
        "\n",
        "    maximum_data = max(data_length_list)\n",
        "    print(\"maximum_data\",maximum_data)\n",
        "\n",
        "\n",
        "    ratio = math.floor(( 4 / 6 )* maximum_data)\n",
        "    print(\"ratio\",ratio)\n",
        "    loop_count = 0\n",
        "    train_upsampled = []\n",
        "    for i in data_length_list:\n",
        "      #print(i)\n",
        "      #print(len(data_list[loop_count]))\n",
        "      if i < ratio:\n",
        "        df_upsampled = resample(data_list[loop_count],replace=True,n_samples=ratio,random_state=123)\n",
        "      else:\n",
        "        df_upsampled = resample(data_list[loop_count],replace=True,n_samples=i,random_state=123)\n",
        "      \n",
        "      train_upsampled.append(df_upsampled)\n",
        "      loop_count = loop_count + 1\n",
        "\n",
        "    df_res = pd.concat(train_upsampled)\n",
        "    train = df_res.copy(deep = True)\n",
        "    train_size_list.append(train_size)\n",
        "    i_list.append(i)\n",
        "    j_list.append(j)\n",
        "    print(\"length of the UL received\",len(unlabel_1))\n",
        "    \n",
        "   \n",
        "    #cleaning\n",
        "    import nltk\n",
        "    import re\n",
        "    import string\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "    stopword=nltk.corpus.stopwords.words('english')\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    wl= WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(text):\n",
        "      text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "      tokens = re.split('\\W+',text)\n",
        "      text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "      return text\n",
        "\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "    #X_tfidf = tfidf_vect.fit_transform(train['Sentence'])\n",
        "    X_tfidf = tfidf_vect.fit_transform(train['text'])\n",
        "    print(X_tfidf.shape)\n",
        "\n",
        "    #Read test data\n",
        "    test = pd.read_csv(r'/content/drive/My Drive/Research/test_data.csv')\n",
        "\n",
        "    #Test data cleaning\n",
        "    test['Target']=test['Target'].replace(['Others'],'Invalid')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "    test['Sentence'] = test['Sentence'].str.replace('[^\\w\\s]','')\n",
        "    from nltk.corpus import stopwords\n",
        "    words = stopwords.words('english')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "    t_p = tfidf_vect.transform(test['Sentence'])\n",
        "\n",
        "    import lightgbm as lgb\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    classifier_rf = RandomForestClassifier(n_estimators = 350, criterion = 'gini', max_features = 'auto', random_state = 42)\n",
        "    classifier_lgb = lgb.LGBMClassifier()\n",
        "\n",
        "    X_train, x_val, Y_train, y_val = train_test_split(X_tfidf,train['Target'],test_size=0.20,random_state=42)\n",
        "\n",
        "    X_train_whole = X_tfidf\n",
        "    Y_train_whole = train['Target']\n",
        "    #X_train_whole, x_val_whole, Y_train_whole, y_val_whole = train_test_split(X_tfidf,train['Target'],test_size=0.1,random_state=42)\n",
        "\n",
        "    classifier_rf.fit(X_train, Y_train)\n",
        "    classifier_lgb.fit(X_train, Y_train)\n",
        "\n",
        "    val_pred_rf = classifier_rf.predict(x_val)\n",
        "    val_pred_lgb = classifier_lgb.predict(x_val)\n",
        "\n",
        "\n",
        "    Accuracy_score_rf = accuracy_score(y_val,val_pred_rf)\n",
        "    print(\"Accuracy_score_rf \",Accuracy_score_rf)\n",
        "    Accuracy_score_lgb = accuracy_score(y_val,val_pred_lgb)\n",
        "    print(\"Accuracy_score_lgb \",Accuracy_score_lgb)\n",
        "\n",
        "    classification_report_test_rf = classification_report(y_val,val_pred_rf)\n",
        "    print(\"classification report \",classification_report_test_rf)\n",
        "    classification_report_test_lgb = classification_report(y_val,val_pred_lgb)\n",
        "    print(\"classification report \",classification_report_test_lgb)\n",
        "\n",
        "\n",
        "    f1_score_rf = f1_score(y_val,val_pred_rf,average='weighted')\n",
        "    print(\" f1 score test \",f1_score_rf )\n",
        "    f1_score_lgb = f1_score(y_val,val_pred_lgb, average='weighted')\n",
        "    print(\" f1 score test \",f1_score_lgb )\n",
        "\n",
        "\n",
        "    if Accuracy_score_rf > Accuracy_score_lgb:\n",
        "      B = classifier_rf\n",
        "    else:\n",
        "      B = classifier_lgb\n",
        "\n",
        "    B.fit(X_train_whole,Y_train_whole)\n",
        "    test_pred = B.predict(t_p)\n",
        "    accuracy_test = accuracy_score(test['Target'],test_pred)\n",
        "    print('Accuracy test data', accuracy_test)\n",
        "    f1_score_test = f1_score(test['Target'],test_pred, average='weighted')\n",
        "    print(\" f1 score test \",f1_score_test )\n",
        "    f1_score_test_list.append(f1_score_test)\n",
        "    record_f1_score.append(f1_score_test)\n",
        "    classification_report_test_data = classification_report(test['Target'],test_pred)\n",
        "    record_CR.append(classification_report_test_data)\n",
        "    print(\"classification report \",classification_report_test_data)\n",
        "    class_x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "    class_pred_unlabel_1 = B.predict(class_x_un1)\n",
        "    unlabel_1['Target']=class_pred_unlabel_1\n",
        "    frame_1 = [train,unlabel_1]\n",
        "    train_1 = pd.concat(frame_1)\n",
        "    print(len(train_1))\n",
        "    \n",
        "    \n",
        "    #Open a text file for writing the outputs\n",
        "    with open(r'/content/drive/My Drive/Results/Co_Training_2C/Result01.txt', 'a') as writefile:\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" Co-training results \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" train_size \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(train_size))\n",
        "        writefile.write(\" Accuracy_score_rf = \")\n",
        "        writefile.write(str(Accuracy_score_rf))\n",
        "        writefile.write(\" Accuracy_score_lgb = \")\n",
        "        writefile.write(str(Accuracy_score_lgb))\n",
        "        writefile.write(\" classification_report_test_rf = \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(classification_report_test_rf))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_lgb = \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(classification_report_test_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_rf = \")\n",
        "        writefile.write(str(f1_score_rf))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_lgb = \")\n",
        "        writefile.write(str(f1_score_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" Results on test data \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_test = \")\n",
        "        writefile.write(str(f1_score_test))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_data = \")\n",
        "        writefile.write(str(classification_report_test_data))\n",
        "        writefile.write(\"\\n\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    return train_1,train_size_list,f1_score_test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmdmtFC6nRYv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOAsDaInzdeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66802dd9-93b0-4315-ad44-ab5731338ba8"
      },
      "source": [
        "import numpy as np \n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQTLi1-4ziuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1786b8f0-3f13-485e-c442-b5700c87f30c"
      },
      "source": [
        "#Read the unlabeled data\n",
        "unlabel = pd.read_csv(r'/content/drive/My Drive/Research/Unlabeled_data.csv')\n",
        "\n",
        "#unlabeled data cleaning\n",
        "del unlabel['Complete']\n",
        "del unlabel['Unnamed: 0']\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "unlabel['text'] = unlabel['text'].str.replace('[^\\w\\s]','')\n",
        "from nltk.corpus import stopwords\n",
        "words = stopwords.words('english')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: TextBlob(x).words)\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "unlabel.head()\n",
        "len(unlabel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "537703"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLlEO8v6znBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff0bba7-9df7-437f-ffe6-cab7e79b297d"
      },
      "source": [
        "\n",
        "#Read the labeled data\n",
        "\n",
        "train1 = pd.read_csv('/content/drive/My Drive/Research/train_data1.csv')\n",
        "train2 = pd.read_csv('/content/drive/My Drive/Research/train_data2.csv')\n",
        "train3 = pd.read_csv('/content/drive/My Drive/Research/train_data3.csv')\n",
        "train4 = pd.read_csv('/content/drive/My Drive/Research/train_data4.csv')\n",
        "train5 = pd.read_csv('/content/drive/My Drive/Research/train_data5.csv')\n",
        "train6 = pd.read_csv('/content/drive/My Drive/Research/train_data6.csv')\n",
        "train7 = pd.read_csv('/content/drive/My Drive/Research/train_data7.csv')\n",
        "train8 = pd.read_csv('/content/drive/My Drive/Research/train_data8.csv')\n",
        "train9 = pd.read_csv('/content/drive/My Drive/Research/train_data9.csv')\n",
        "train10 = pd.read_csv('/content/drive/My Drive/Research/train_data10.csv')\n",
        "train_highKappa = pd.read_csv('/content/drive/My Drive/Research/train_data_highkappa.csv')\n",
        "train = train1\n",
        "train_list = [train2,train3,train4,train5,train6,train7,train8,train9,train10,train_highKappa]\n",
        "for i in train_list:\n",
        "    #print(i)\n",
        "    train = train.append(i)\n",
        "train.sort_values(\"Sentence\", inplace = True)\n",
        "print(len(train))\n",
        "train = train.drop_duplicates(subset =\"Sentence\")\n",
        "train['Target'].unique()\n",
        "train['Target']=train['Target'].replace(['Others'],'Invalid')\n",
        "train['Target'].unique()\n",
        "print(len(train))\n",
        "train = train.rename(columns={'Sentence':'text'})\n",
        "all_Data_train_size = len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37711\n",
            "4416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYULt4Y5zsLO"
      },
      "source": [
        "\n",
        "length_list = [500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBuxWGzTzvf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14a8f3a-ec71-4302-edb8-9c95496448a6"
      },
      "source": [
        "len(length_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocucADNz13c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1e86ff-ef0a-4d06-ed63-c0698db1cb62"
      },
      "source": [
        "j=0\n",
        "iteration = 0\n",
        "i_list = []\n",
        "j_list = []\n",
        "f1_score_test_list = []\n",
        "train_size_list =[]\n",
        "\n",
        "for i in length_list:\n",
        "  print(\"iteration \",iteration)\n",
        "  print(i)\n",
        "  print(j)\n",
        "  unlabel_chunk = unlabel[j:i]\n",
        "  train,op_train_size_list,op_f1_score_test_list = training(unlabel_chunk,train,i,j)\n",
        "  j=i\n",
        "  iteration = iteration + 1\n",
        "  print(\"length\",len(unlabel_chunk))\n",
        "    \n",
        "with open(r'/content/drive/My Drive/Results/Co_Training_2C/Result01.txt', 'a') as writefile:\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" Co-training results \")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" train size \")\n",
        "    writefile.write(str(all_Data_train_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_train_size_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_train_size_list))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_f1_score_test_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_f1_score_test_list))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration  0\n",
            "500\n",
            "0\n",
            "maximum_data 2253\n",
            "ratio 1502\n",
            "@ 1502\n",
            "@ 1502\n",
            "@ 2253\n",
            "@ 1502\n",
            "@ 1502\n",
            "@ 1502\n",
            "length of the UL received 500\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "(9763, 6515)\n",
            "Accuracy_score_rf  0.9482846902201741\n",
            "Accuracy_score_lgb  0.8965693804403482\n",
            "classification report                    precision    recall  f1-score   support\n",
            "\n",
            "        Analysis       0.94      0.90      0.92       321\n",
            "      Conclusion       0.97      0.98      0.98       299\n",
            "           Facts       0.94      0.90      0.92       435\n",
            "         Invalid       0.89      0.96      0.92       294\n",
            "           Issue       0.98      1.00      0.99       295\n",
            "Rule/Law/Holding       0.98      0.97      0.98       309\n",
            "\n",
            "        accuracy                           0.95      1953\n",
            "       macro avg       0.95      0.95      0.95      1953\n",
            "    weighted avg       0.95      0.95      0.95      1953\n",
            "\n",
            "classification report                    precision    recall  f1-score   support\n",
            "\n",
            "        Analysis       0.88      0.80      0.84       321\n",
            "      Conclusion       0.92      0.98      0.95       299\n",
            "           Facts       0.86      0.86      0.86       435\n",
            "         Invalid       0.84      0.86      0.85       294\n",
            "           Issue       0.95      0.97      0.96       295\n",
            "Rule/Law/Holding       0.94      0.94      0.94       309\n",
            "\n",
            "        accuracy                           0.90      1953\n",
            "       macro avg       0.90      0.90      0.90      1953\n",
            "    weighted avg       0.90      0.90      0.90      1953\n",
            "\n",
            " f1 score test  0.9481118645910419\n",
            " f1 score test  0.8958878995944538\n",
            "Accuracy test data 0.6353166986564299\n",
            " f1 score test  0.6287483079542432\n",
            "classification report                    precision    recall  f1-score   support\n",
            "\n",
            "        Analysis       0.48      0.31      0.38        77\n",
            "      Conclusion       0.70      0.73      0.72        26\n",
            "           Facts       0.72      0.78      0.75       267\n",
            "         Invalid       0.44      0.57      0.49        83\n",
            "           Issue       0.89      0.50      0.64        34\n",
            "Rule/Law/Holding       0.57      0.47      0.52        34\n",
            "\n",
            "        accuracy                           0.64       521\n",
            "       macro avg       0.63      0.56      0.58       521\n",
            "    weighted avg       0.64      0.64      0.63       521\n",
            "\n",
            "10263\n",
            "length 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:146: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWN4HsuNz61p"
      },
      "source": [
        "with open(r'/content/drive/My Drive/Results/Co_Training_2C/Result01.txt', 'a') as writefile:\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" Co-training results \")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" train size \")\n",
        "    writefile.write(str(all_Data_train_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_train_size_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_train_size_list))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_f1_score_test_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_f1_score_test_list))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSIYJ59AoQGy"
      },
      "source": [
        "with open(r'/content/drive/My Drive/Results/Co_Training_2C/Result01.txt', 'a') as writefile:\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"record_unlabel_list\")\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(str(record_unlabel_list))\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"record_f1_score\")\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(str(record_f1_score))\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(\"record_CR\")\n",
        "  writefile.write(\"\\n\")\n",
        "  writefile.write(str(record_CR))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}